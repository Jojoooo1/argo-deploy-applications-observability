apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: observability-tempo-helm
  namespace: argocd

  # Add this finalizer ONLY if you want these to cascade delete (A cascade delete, deletes both the app and its resources, rather than only the app.)
  # finalizers:
  #   - resources-finalizer.argocd.argoproj.io

spec:
  project: default
  syncPolicy:
    syncOptions:
      - CreateNamespace=true
      - PrunePropagationPolicy=foreground

  source:
    chart: tempo
    repoURL: "https://grafana.github.io/helm-charts"
    targetRevision: 1.7.1
    helm:

      # https://github.com/grafana/helm-charts/blob/main/charts/tempo/values.yaml
      valuesObject:
      
        fullnameOverride: tempo

        tempo:
          retention: 720h # 30d
          # memBallastSizeMbs: 1024 # usually recommended to be around 40% of the memory limit
          resources:
            requests: 
              memory: 1Gi
              cpu: 150m
            limits:
              memory: 1Gi # 7Gi for production
              cpu: 150m # 1 for production
            
          global_overrides:
            # In high volume cenario we need to increase this value.
            max_traces_per_user: 20000
          
          # https://github.com/grafana/tempo/blob/main/docs/tempo/website/configuration/_index.md#storage
          # storage:
          #   trace:
          #     backend: gcs
          #     gcs:
          #       bucket_name: <bucket_name>

          metricsGenerator:
            enabled: true
            remoteWriteUrl: "http://kube-prometheus-stack-prometheus.observability:9090/api/v1/write"

        # Needed to override because traces_storage not provided: https://github.com/grafana/tempo/issues/3064
        config: |
          multitenancy_enabled: {{ .Values.tempo.multitenancyEnabled }}
          usage_report:
            reporting_enabled: {{ .Values.tempo.reportingEnabled }}
          compactor:
            compaction:
              block_retention: {{ .Values.tempo.retention }}
          distributor:
            receivers:
              {{- toYaml .Values.tempo.receivers | nindent 8 }}
          ingester:
            {{- toYaml .Values.tempo.ingester | nindent 6 }}
          server:
            {{- toYaml .Values.tempo.server | nindent 6 }}
          storage:
            {{- toYaml .Values.tempo.storage | nindent 6 }}
          querier:
            {{- toYaml .Values.tempo.querier | nindent 6 }}
          query_frontend:
            {{- toYaml .Values.tempo.queryFrontend | nindent 6 }}
          overrides:
            {{- toYaml .Values.tempo.global_overrides | nindent 6 }}
            {{- if .Values.tempo.metricsGenerator.enabled }}
                metrics_generator_processors:
                - 'service-graphs'
                - 'span-metrics'
                - 'local-blocks'

          metrics_generator:
                storage:
                  path: "/tmp/tempo/generator/wal"
                  remote_write:
                    - url: {{ .Values.tempo.metricsGenerator.remoteWriteUrl }}
                traces_storage:
                  path: "/tmp/tempo/generator/traces"
            {{- end }}

        serviceMonitor:
          enabled: true
          namespace: observability
          additionalLabels:
            prometheus.io/scrap-with: kube-prometheus-stack

        persistence:
          enabled: true
          size: 1Gi

        # serviceAccount:
        #   annotations:
        #     iam.gke.io/gcp-service-account: tempo-storage@${ARGOCD_ENV_PROJECT}.iam.gserviceaccount.com

  destination:
    server: "https://kubernetes.default.svc"
    namespace: observability
